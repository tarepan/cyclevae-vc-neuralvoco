<div align="center">

# CycVAE-MWDLP VC <!-- omit in toc -->
<!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook] -->
[![Paper](http://img.shields.io/badge/paper-arxiv.2105.09858-B31B1B.svg)][paper]  

</div>

Clone of official implmentation of voice conversion system "CycVAE-MWDLP VC".

<!-- generated by [Markdown All in One](https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one) -->
- [Demo](#demo)
- [How to Use](#how-to-use)
    - [Requirements:](#requirements)
    - [install](#install)
    - [Steps for real-time low-latency decoding with CPU:](#steps-for-real-time-low-latency-decoding-with-cpu)
- [Original paper](#original-paper)
- [Details](#details)
- [Contact](#contact)

## Demo
- MWDLP
  - model: [demo_mwdlp-10bit_emb-v2_vcc20](https://drive.google.com/file/d/1hR7N-iCSUMNx9P-pDVxftGIIKLLyXsnt/view?usp=sharing)
  - sample: [samples_demo_mwdlp-10bit_emb-v2_vcc20](https://drive.google.com/drive/folders/1by_BO-fkeouDgTZBWEeu6EnzaX8UgHL8?usp=sharing)
- VC
  - model: [demo_sparse-cyclevae-weightembv2-smpl_jnt_mwdlp-10bit_emb_vcc20](https://drive.google.com/file/d/1LtuQmnUP45iWoREbPK0vBTdu2tDZKYeT/view?usp=sharing)
  - sample: [samples_demo_sparse-cyclevae-weightembv2-smpl_jnt_mwdlp-10bit_emb_vcc20](https://drive.google.com/drive/folders/1PanNaqsOccCImHECywzsaX6mFwausznz?usp=sharing)

## How to Use
<!-- ### Quick training <- omit in toc ->
Jump to **[Notebook in Google Colaboratory][notebook]**, then Run. that's all!!  
 -->
### Install <!-- omit in toc -->
#### Requirements:
- UNIX
- 3.6 <= python <= 3.9
- CUDA 11.1
- jq
- make
- gcc

#### install
```bash
$ cd tools
$ make
$ cd ..
```

### Training <!-- omit in toc -->
1. Data preparation and preprocessing
2. VC and neural vocoder models training [~ 2.5 and 4 days each, respectively]
3. VC fine-tuning with fixed neural vocoder [~ 2.5 days]
4. VC decoder fine-tuning with fixed encoder and neural vocoder [~ 2.5 days]

#### Steps for real-time low-latency decoding with CPU:
1. Dump and compile models
2. Decode

Real-time implementation is based on [LPCNet](https://github.com/mozilla/LPCNet/).

<!-- ### Training Speed <!- omit in toc ->
X3.37 [iter/sec] @ NVIDIA T4 Google Colaboratory (AMP+)
 -->
## Original paper
[![Paper](http://img.shields.io/badge/paper-arxiv.2105.09858-B31B1B.svg)][paper]  
<!-- https://arxiv2bibtex.org/?q=2105.09858&format=bibtex -->
```
@misc{2105.09858,
Author = {Patrick Lumban Tobing and Tomoki Toda},
Title = {Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction},
Year = {2021},
Eprint = {arXiv:2105.09858},
}
```

[paper]:https://arxiv.org/abs/2105.09858
<!-- [notebook]:https://colab.research.google.com/github/tarepan/Scyclone-PyTorch/blob/main/Scyclone_PyTorch.ipynb -->

## Details
Check

- VC + neural vocoder: **egs/cycvae_mwdlp_vcc20/README.md**
- neural vocoder only: **egs/mwdlp_vcc20/README.md**

## References

[1] [High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling](https://arxiv.org/abs/2105.09856.pdf)

[2] [Low-latency real-time non-parallel voice conversion based on cyclic variational autoencoder and multiband WaveRNN with data-driven linear prediction](https://arxiv.org/pdf/2105.09858.pdf)


## Contact
Please check original repository.  
